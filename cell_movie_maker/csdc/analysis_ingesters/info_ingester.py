import chaste_simulation_database_connector as csdc
from ...experiment import Experiment
from ...simulation import Simulation
from ...simulation_timepoint import SimulationTimepoint
from ..analysis_ingest import AnalysisIngest
from ...config import Config
import typing
import logging
import tqdm
import pathlib
import pandas as pd


def chunk(l, n):
    for i in range(0, len(l), n):
        yield l[i:i+n]

class InfoIngester(AnalysisIngest):
    """
    Class to write preprocessing data which has been stored in an 'info' file to database.  
    Preprocessing data calculates basic statistics on each timepoint in a simulation, resulting in a table of results (rows=timesteps, columns=simple metrics).  
    '''
    Looks for each simulation's info file in folder configured in `Config.output_folder`.  
    Info file is generated by an `AbstractProcessor`, and has path: '<Config.output_folder>/info/sim_<ID>.csv'.  

    Attributes
    ----------
    mode : str
        Data format to store to database (default = 'parquet')
    """
    def __init__(self, *args, **kwargs):
        """
        Constructor
        
        Parameters
        ----------
        db : csdc.Connection
            Database connection
        skip_existing : bool, optional (default True)
            Skip analysis if analysis with matching metadata is already in database
        """
        super().__init__(*args, **kwargs)
        self.mode:str='parquet'

    def ingest_experiment(self, experiment:Experiment, batch_size:int=None, disable_tqdm:bool=False)->None:
        """
        Store preprocessing results from simulations in experiment

        Parameters
        ----------
        eperiment : Experiment
            Experiment containing simulations to process
        batch_size : int|None, optional (default None)
            Number of simulations to process in each batch
        disable_tqdm : bool, optional (default=False)
            If true disables tqdm printing a progress bar
        
        
        Returns
        -------
        None
        """
        is_batched:bool = batch_size != None
        if batch_size is None: batch_size = len(experiment.sim_ids)
        for i, sims_batch in enumerate(chunk(experiment.sim_ids, batch_size)):
            if is_batched: logging.info(f"Batch {i}...")
            self.db.add_bulk_simulations([dict(experiment=experiment.name, iteration=int(sim_id)) for sim_id in sims_batch], commit=True, close_connection=True)
            results = []
            for sim_id in tqdm.tqdm(sims_batch, disable=disable_tqdm):
                info_file = Config.output_folder.joinpath(experiment.name, "info", f'sim_{sim_id}.csv')
                if not info_file.exists():
                    logging.error(f"No such file {info_file}")
                    continue
                info = pd.read_csv(info_file, index_col='timestep')
                if self.mode == 'json': analysis_value = info.to_json()
                elif self.mode == 'parquet': analysis_value = info.to_parquet(index=True)
                else: raise RuntimeError(f'Mode \"{self.mode}\" not implemented, try "json" or "parquet"')
                results.append(dict(experiment=experiment.name, iteration=sim_id, timestep=-1, analysis_name="cellcounts", analysis_value=analysis_value))
            self.db.add_bulk_analysis(results, commit=True, close_connection=True)
        self.db.commit()
        self.db.close_connection()
            
